---
# Max kernels for AI87, all 4 groups

arch: test
dataset: test_maxkern0123

layers:
  # Group 0
  - pad: 1
    activate: ReLU
    out_offset: 0x2000
    processors: 0x0000000000000001
    output_processors: 0xffffffffffffffff
    data_format: HWC
    op: conv2d
  - pad: 1
    in_channels: 1
    in_skip: 15
    activate: ReLU
    out_offset: 0x0
    processors: 0x0000000000000001
    output_processors: 0xffffffffffffffff
    op: conv2d
  - pad: 1
    in_channels: 1
    in_skip: 15
    activate: ReLU
    out_offset: 0x2000
    processors: 0x0000000000000001
    output_processors: 0xffffffffffffffff
    op: conv2d
  - pad: 1
    in_channels: 1
    in_skip: 15
    activate: ReLU
    out_offset: 0x0
    processors: 0x0000000000000001
    output_processors: 0xffffffffffffffff
    op: conv2d
  - pad: 1
    in_channels: 1
    in_skip: 15
    activate: ReLU
    out_offset: 0x2000
    processors: 0x0000000000000001
    output_processors: 0xffffffffffffffff
    op: conv2d
  # Group 1
  - pad: 1
    in_skip: 15
    in_channel_skip: 16
    activate: ReLU
    out_offset: 0x0
    processors: 0x0000000000010000
    output_processors: 0xffffffffffffffff
    op: conv2d
  - pad: 1
    in_channels: 1
    in_channel_skip: 16
    in_skip: 15
    activate: ReLU
    out_offset: 0x2000
    processors: 0x0000000000010000
    output_processors: 0xffffffffffffffff
    op: conv2d
  - pad: 1
    in_channels: 1
    in_channel_skip: 16
    in_skip: 15
    activate: ReLU
    out_offset: 0x0
    processors: 0x0000000000010000
    output_processors: 0xffffffffffffffff
    op: conv2d
  - pad: 1
    in_channels: 1
    in_channel_skip: 16
    in_skip: 15
    activate: ReLU
    out_offset: 0x2000
    processors: 0x0000000000010000
    output_processors: 0xffffffffffffffff
    op: conv2d
  - pad: 1
    in_channels: 1
    in_channel_skip: 16
    in_skip: 15
    activate: ReLU
    out_offset: 0x0
    processors: 0x0000000000010000
    output_processors: 0xffffffffffffffff
    op: conv2d
  # Group 2
  - pad: 1
    in_skip: 15
    in_channel_skip: 32
    activate: ReLU
    out_offset: 0x2000
    processors: 0x0000000100000000
    output_processors: 0xffffffffffffffff
    op: conv2d
  - pad: 1
    in_channels: 1
    in_channel_skip: 32
    in_skip: 15
    activate: ReLU
    out_offset: 0x0
    processors: 0x0000000100000000
    output_processors: 0xffffffffffffffff
    op: conv2d
  - pad: 1
    in_channels: 1
    in_channel_skip: 32
    in_skip: 15
    activate: ReLU
    out_offset: 0x2000
    processors: 0x0000000100000000
    output_processors: 0xffffffffffffffff
    op: conv2d
  - pad: 1
    in_channels: 1
    in_channel_skip: 32
    in_skip: 15
    activate: ReLU
    out_offset: 0x0
    processors: 0x0000000100000000
    output_processors: 0xffffffffffffffff
    op: conv2d
  - pad: 1
    in_channels: 1
    in_channel_skip: 32
    in_skip: 15
    activate: ReLU
    out_offset: 0x2000
    processors: 0x0000000100000000
    output_processors: 0xffffffffffffffff
    op: conv2d
  # Group 3
  - pad: 1
    in_skip: 15
    in_channel_skip: 48
    activate: ReLU
    out_offset: 0x0
    processors: 0x0001000000000000
    output_processors: 0xffffffffffffffff
    op: conv2d
  - pad: 1
    in_channels: 1
    in_channel_skip: 48
    in_skip: 15
    activate: ReLU
    out_offset: 0x2000
    processors: 0x0001000000000000
    output_processors: 0xffffffffffffffff
    op: conv2d
  - pad: 1
    in_channels: 1
    in_channel_skip: 48
    in_skip: 15
    activate: ReLU
    out_offset: 0x0
    processors: 0x0001000000000000
    output_processors: 0xffffffffffffffff
    op: conv2d
  - pad: 1
    in_channels: 1
    in_channel_skip: 48
    in_skip: 15
    activate: ReLU
    out_offset: 0x2000
    processors: 0x0001000000000000
    output_processors: 0xffffffffffffffff
    op: conv2d
  - pad: 1
    in_channels: 1
    in_channel_skip: 48
    in_skip: 15
    activate: ReLU
    out_offset: 0x0
    processors: 0x0001000000000000
    op: conv2d
