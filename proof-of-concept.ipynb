{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf43be7f",
   "metadata": {},
   "source": [
    "### Proof of concept using PyTorch before implementing the model on the microcontroller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "42ee2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5912bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"processed_data/raw/\"\n",
    "SAMPLE_RATE = 16000\n",
    "NUM_CLASSES = 2  # change this based on your keywords\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "USE_MFCC = True  # Set to False to use spectrogram instead\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a9cc585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and Preprocessing\n",
    "\n",
    "class KWSDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, use_mfcc=True):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.use_mfcc = use_mfcc\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        y, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "\n",
    "        # Optional: Padding/truncation\n",
    "        if len(y) < SAMPLE_RATE:\n",
    "            y = np.pad(y, (0, SAMPLE_RATE - len(y)))\n",
    "        else:\n",
    "            y = y[:SAMPLE_RATE]\n",
    "\n",
    "        # Feature extraction\n",
    "        if self.use_mfcc:\n",
    "            features = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=32) \n",
    "            features = (features - np.mean(features)) / (np.std(features) + 1e-6) # Normalize\n",
    "        else:\n",
    "            features = librosa.stft(y)\n",
    "            features = np.abs(features)\n",
    "\n",
    "        features = features[np.newaxis, ...]  # Add channel dimension\n",
    "        return torch.tensor(features, dtype=torch.float32), torch.tensor(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3c4ecae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label names: ['cough', 'non_cough']\n",
      "Label map: {'cough': 0, 'non_cough': 1}\n",
      "Found 8588 files for label 'cough'\n",
      "Found 25742 files for label 'non_cough'\n"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "\n",
    "# Example assumes structure: DATA_DIR/class_name/*.wav\n",
    "def load_data(data_dir):\n",
    "    all_paths = []\n",
    "    all_labels = []\n",
    "    label_names = sorted([d for d in os.listdir(data_dir) if not d.startswith('.') and os.path.isdir(os.path.join(data_dir, d))])\n",
    "    print(f\"Label names: {label_names}\")\n",
    "    label_map = {name: i for i, name in enumerate(label_names)}\n",
    "    print(f\"Label map: {label_map}\")\n",
    "\n",
    "    for label in label_names:\n",
    "        class_dir = os.path.join(data_dir, label)\n",
    "        wavs = list(Path(class_dir).rglob(\"*.wav\"))\n",
    "        print(f\"Found {len(wavs)} files for label '{label}'\")\n",
    "        for wav_path in wavs:\n",
    "            all_paths.append(str(wav_path))\n",
    "            all_labels.append(label_map[label]) # contain 0 or 1 depending on class\n",
    "\n",
    "    return all_paths, all_labels, label_map\n",
    "\n",
    "file_paths, labels, label_map = load_data(DATA_DIR)\n",
    "X_train, X_test, y_train, y_test = train_test_split(file_paths, labels, test_size=0.1, stratify=labels)\n",
    "\n",
    "train_dataset = KWSDataset(X_train, y_train, use_mfcc=USE_MFCC)\n",
    "test_dataset = KWSDataset(X_test, y_test, use_mfcc=USE_MFCC)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "75d8c86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test data: 3433\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of test data: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9fd7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating the KWSetwork implemented in the the MAXIM examples\n",
    "class PyTorchAI85Net20(nn.Module): \n",
    "    def __init__(self, num_classes=21, num_channels=1, dimensions=(64, 64), \n",
    "                 fc_inputs=30, bias=False):\n",
    "        super().__init__()\n",
    "        self.dim = dimensions[0]\n",
    "\n",
    "        # Layer 1: Conv + ReLU\n",
    "        self.conv1 = nn.Conv2d(num_channels, 15, kernel_size=3, padding=1, bias=bias)\n",
    "        \n",
    "        # Layer 2: MaxPool + Conv + ReLU\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # 16x16\n",
    "        self.conv2 = nn.Conv2d(15, 30, kernel_size=3, padding=1, bias=bias)\n",
    "        \n",
    "        # Layer 3: MaxPool + Conv + ReLU\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # 8x8\n",
    "        self.conv3 = nn.Conv2d(30, 60, kernel_size=3, padding=1, bias=bias)\n",
    "        \n",
    "        # Layer 4: MaxPool + Conv + ReLU\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) # 4x4\n",
    "        self.conv4 = nn.Conv2d(60, 30, kernel_size=3, padding=1, bias=bias)\n",
    "        \n",
    "        # Layer 5: MaxPool + Conv + ReLU\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2) # 2x2\n",
    "        self.conv5 = nn.Conv2d(30, 30, kernel_size=3, padding=1, bias=bias)\n",
    "        \n",
    "        # Layer 6: Conv + ReLU\n",
    "        self.conv6 = nn.Conv2d(30, fc_inputs, kernel_size=3, padding=1, bias=bias)\n",
    "        \n",
    "        # Final classification layer\n",
    "        self.fc = nn.Linear(fc_inputs * (self.dim//16)**2, num_classes, bias=True)\n",
    "\n",
    "        # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through all layers\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        x = self.pool3(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        \n",
    "        x = self.pool4(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        \n",
    "        x = self.pool5(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        \n",
    "        x = F.relu(self.conv6(x))\n",
    "        \n",
    "        # Flatten and classify\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Usage example:\n",
    "#model = PyTorchAI85Net20(num_classes=2, dimensions=(32, 32))\n",
    "#input_tensor = torch.randn(1, 1, 64, 64)  # Batch size 1, 1 channel, 64x64\n",
    "#output = model(input_tensor)\n",
    "#print(f\"Output shape: {output.shape}\")  # Should be torch.Size([1, 21])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5fae8665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [04:55<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 165.427, Acc: 85.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [03:52<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss: 88.882, Acc: 92.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [03:57<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Loss: 63.266, Acc: 95.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [04:23<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Loss: 49.516, Acc: 96.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [04:01<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Loss: 43.188, Acc: 96.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [04:14<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Loss: 37.366, Acc: 97.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [03:41<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Loss: 29.037, Acc: 97.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [03:41<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Loss: 27.030, Acc: 97.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [03:36<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Loss: 22.809, Acc: 98.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [03:31<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Loss: 18.780, Acc: 98.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [03:41<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Loss: 16.966, Acc: 98.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [03:38<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Loss: 14.665, Acc: 98.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [03:47<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Loss: 14.394, Acc: 98.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [04:04<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Loss: 12.683, Acc: 99.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [03:58<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Loss: 12.734, Acc: 99.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [04:23<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Loss: 9.325, Acc: 99.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [03:59<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Loss: 10.196, Acc: 99.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [04:07<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Loss: 10.569, Acc: 99.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [04:43<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Loss: 8.672, Acc: 99.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [04:03<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Loss: 7.527, Acc: 99.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#model = SimpleCNN(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "model = PyTorchAI85Net20(num_classes=NUM_CLASSES, dimensions=(32, 32)).to(DEVICE)\n",
    "\n",
    "# ============================================\n",
    "# âš™ï¸ 6. Training Loop\n",
    "# ============================================\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, targets in tqdm(train_loader):\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} - Loss: {running_loss:.3f}, Acc: {100.*correct/total:.2f}%\")\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2fdeabe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.91%\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# ðŸ“ˆ 7. Evaluation\n",
    "# ============================================\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    print(f\"Test Accuracy: {100. * correct / total:.2f}%\")\n",
    "\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b7d99a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'PyTorchAI85Net20_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f23a7a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyTorchAI85Net20(\n",
       "  (conv1): Conv2d(1, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(15, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(30, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(60, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv5): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv6): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (fc): Linear(in_features=120, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = PyTorchAI85Net20(num_classes=NUM_CLASSES, dimensions=(32, 32))\n",
    "loaded_model.load_state_dict(torch.load('PyTorchAI85Net20_weights.pth', weights_only=True))\n",
    "loaded_model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mfcc_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
